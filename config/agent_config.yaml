paths:
  base_dir: "/home/jovyan/nmt-srv-shared/users/thanhmv/practice_research/AI_agent/instruction-data-generator"
  cache_dir: "/home/jovyan/nmt-srv-shared/users/thanhmv/practice_research/AI_agent/instruction-data-generator/.cache"
  model_dir: "/home/jovyan/nmt-srv-shared/users/thanhmv/practice_research/AI_agent/instruction-data-generator/models"

agent:
  name: "InstructionDataGenerator"
  version: "1.0.0"
  
  # Input processing settings
  input_processing:
    max_workers: 4
    batch_size: 100
    reprocess_existing: true
    max_file_size_mb: 50
    supported_formats:
      documents:
        - ".txt"
        - ".md"
        - ".doc"
        - ".docx"
        - ".pdf"
        - ".ppt"
        - ".pptx"
        - ".xls"
        - ".xlsx"
      images:
        - ".png"
        - ".jpg"
        - ".jpeg"
        - ".gif"
        - ".bmp"

  data_processing:
    batch_size: 32
    num_workers: 4
    
  # Instruction generation settings
  instruction_generation:
    min_question_length: 10
    max_question_length: 150
    min_answer_length: 20
    max_answer_length: 500
    max_instructions_per_doc: 10
    min_instruction_length: 10
    max_instruction_length: 2000
    
    templates:
      - name: "task_description"
        weight: 1.0
      - name: "question_answer"
        weight: 1.0
      - name: "step_by_step"
        weight: 0.8
      - name: "compare_contrast"
        weight: 0.6
    
    augmentation:
      enabled: true
      techniques:
        - "paraphrase"
        - "generalize"
        - "specific"
      max_variants: 3

    answer_extraction:
      extract_entities: true
      extract_phrases: true
      extract_facts: true
      entity_types: ["PERSON", "ORG", "GPE", "LOC", "DATE", "EVENT", "WORK_OF_ART"]
      min_answer_length: 3
      max_answer_length: 100
      min_fact_score: 0.6
      max_answers: 50
      spacy_model: "en_core_web_sm"
      duplicate_threshold: 0.85
      
    question_generation:
      use_question_classifier: true
      min_question_length: 5
      max_question_length: 30
      min_answer_length: 3
      max_answer_length: 200
      min_qa_score: 0.6
      max_questions: 30
      duplicate_threshold: 0.85
      spacy_model: "en_core_web_sm"
      
      custom_templates:
        visual:
          layout:
            - "How is the content laid out in this image?"
            - "What is the visual structure or arrangement?"
          style:
            - "What is the visual style or design of this image?"
            - "What artistic or design elements are notable?"
        combined:
          text_layout:
            - "How does the layout support {context}?"
            - "How is {context} enhanced by the visual arrangement?"
          text_style:
            - "How does the visual style relate to {context}?"
            - "What design choices reinforce {context}?"

    # Chunking settings
    chunk_size: 1500  # Maximum chunk size in characters
    chunk_overlap: 150  # Overlap between chunks
    chunk_quality_threshold: 0.6  # Minimum quality score to keep a chunk
    
    # Processing settings
    max_chunks_per_doc: 50  # Maximum chunks to process per document
    min_chunk_length: 100  # Minimum length for a valid chunk
    
    # Generation settings
    max_qa_pairs_per_chunk: 5  # Maximum QA pairs to generate per chunk
    min_qa_pairs_per_chunk: 2  # Minimum QA pairs to generate per chunk
    duplicate_threshold: 0.85  # Similarity threshold for duplicate detection
    
    # Quality thresholds
    min_question_length: 10  # Minimum words in a question
    max_question_length: 50  # Maximum words in a question
    min_answer_length: 5  # Minimum words in an answer
    max_answer_length: 100  # Maximum words in an answer
    min_instruction_length: 15  # Minimum words in an instruction

  # Quality control settings
  quality_control:
    min_quality_score: 0.7
    min_confidence: 0.7
    duplicate_threshold: 0.95
    language_check: true
    content_filters:
      - "profanity"
      - "personal_info"
      - "code_snippets"
    
    metrics:
      - "completeness"
      - "readability"
      - "relevance"
      - "diversity"
      - "answerability"
      - "specificity"
    
    thresholds:
      relevance: 0.6
      rouge_l: 0.3
      answer_presence: 0.8

  # Document processing settings
  document_processing:
    extract_images: true
    ocr_enabled: true
    use_image_captioning: true
    
    image_processing:
      use_object_detection: true
      use_image_captioning: true
      use_visual_qa: true
      use_scene_understanding: true
      use_ocr: true
      object_detection_model: "facebook/detr-resnet-50"
      caption_model: "Salesforce/blip2-opt-2.7b"
      vqa_model: "dandelin/vilt-b32-finetuned-vqa"
      scene_model: "microsoft/git-large-coco"
      detection_threshold: 0.5
      max_objects: 20
      enable_gpu: true
      batch_size: 4
      image_size: 512

    ocr_config:
      language: "eng"
      psm: 3
      oem: 3
      
    pdf_settings:
      extract_images: true
      use_ocr_fallback: true
      dpi: 300
      layout_analysis_flags: 11  # Enable all PyMuPDF layout analysis features
      
      # Enhanced text extraction settings
      text_extraction:
        preserve_formatting: true
        detect_headings: true
        detect_lists: true
        detect_tables: true
        heading_size_threshold: 14
        heading_bold_threshold: 3
        table_confidence: 0.8
        
      # Enhanced image filtering settings
      image_filtering:
        min_size: [100, 100]  # Minimum dimensions to filter out icons
        min_complexity: 0.01  # Minimum edge detection complexity
        min_colors: 5  # Minimum unique colors
        min_area_ratio: 0.01  # Minimum page area ratio
        skip_top_area: 0.1  # Skip images in top 10% (often headers)
        skip_bottom_area: 0.1  # Skip images in bottom 10% (often footers)
        
      # Image quality enhancement
      image_enhancement:
        enable_adaptive_threshold: true
        denoise: true
        auto_deskew: true
        threshold_block_size: 11
        threshold_c: 2
      
      # OCR settings
      ocr_config:
        language: "eng"
        psm: 3  # Page segmentation mode: 3 = auto
        oem: 3  # OCR Engine mode: 3 = default
        preprocessing:
          - deskew
          - denoise
          - enhance_contrast
        confidence_threshold: 60  # Minimum confidence score for OCR text
      
    image_settings:
      min_size: [32, 32]
      max_size: [4096, 4096]
      allowed_formats: ["RGB", "L"]
      preprocessing:
        - resize_if_needed
        - normalize
        - enhance_contrast
    
    text_settings:
      min_chars: 10
      max_chars: 100000
      clean_whitespace: true
      remove_urls: false
      keep_tables: true
      table_format: "markdown"

    max_page_length: 1000
    context_window: 200
    relationship_types:
      - page_content
      - slide_content
      - embedded_content
      - proximity
      - document_section
    visual_elements:
      - figures
      - charts
      - diagrams
      - tables
      - embedded_images
    chunk_size: 512
    chunk_overlap: 50

  # Image processing settings (top-level)
  image_processing:
    use_ocr: true
    use_captioning: true
    ocr_config:
      language: "eng"
      psm: 3
      oem: 3
    caption_model: "Salesforce/blip2-flan-t5-xl"
    batch_size: 16
    max_image_size: [1024, 1024]

  # Model settings
  model:
    instruction_model: "gpt-4"
    quality_model: "text-davinci-003"
    embedding_model: "text-embedding-ada-002"
    
    batch_size: 16
    max_tokens: 2000
    temperature: 0.7
    top_p: 0.9
    presence_penalty: 0.0
    frequency_penalty: 0.0
    
    cache_enabled: true
    cache_ttl_hours: 24

  # Output settings  
  output:
    format: "jsonl"
    include_metadata: true
    save_intermediates: false
    export_format: "jsonl"
    compress: true
    
    splits:
      train: 0.8
      validation: 0.1
      test: 0.1

    save_intermediate: true
    output_dir: data/output/instruction_data
    log_dir: data/logs